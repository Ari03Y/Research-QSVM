{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "OBg4XYxHdabD",
    "outputId": "fbc3119c-a959-4220-c4ae-3ef3f7b0a451"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use raw string to prevent escape sequence interpretation\n",
    "csv_file_path = r'C:\\Users\\a1974\\Downloads\\Research_RIT\\GEMNAME (2).csv'\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "collapsed": true,
    "id": "naICOeqTdcx-",
    "outputId": "7545c381-f0bf-460f-df4d-3747dd2f4786"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24714</td>\n",
       "      <td>204</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "      <td>95</td>\n",
       "      <td>56</td>\n",
       "      <td>2012781</td>\n",
       "      <td>2012781</td>\n",
       "      <td>2012781</td>\n",
       "      <td>2103291</td>\n",
       "      <td>...</td>\n",
       "      <td>304791</td>\n",
       "      <td>305278</td>\n",
       "      <td>304791</td>\n",
       "      <td>20441615954968</td>\n",
       "      <td>229264</td>\n",
       "      <td>229264</td>\n",
       "      <td>229264</td>\n",
       "      <td>230128</td>\n",
       "      <td>229264</td>\n",
       "      <td>20441615954968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317</td>\n",
       "      <td>24612</td>\n",
       "      <td>91</td>\n",
       "      <td>77</td>\n",
       "      <td>102</td>\n",
       "      <td>70</td>\n",
       "      <td>367909</td>\n",
       "      <td>367909</td>\n",
       "      <td>367909</td>\n",
       "      <td>371353</td>\n",
       "      <td>...</td>\n",
       "      <td>371333</td>\n",
       "      <td>372157</td>\n",
       "      <td>371333</td>\n",
       "      <td>20697549917815</td>\n",
       "      <td>225401</td>\n",
       "      <td>225401</td>\n",
       "      <td>225401</td>\n",
       "      <td>226377</td>\n",
       "      <td>225401</td>\n",
       "      <td>20697549917815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>417</td>\n",
       "      <td>204</td>\n",
       "      <td>24127</td>\n",
       "      <td>82</td>\n",
       "      <td>121</td>\n",
       "      <td>87</td>\n",
       "      <td>375407</td>\n",
       "      <td>375407</td>\n",
       "      <td>375407</td>\n",
       "      <td>379037</td>\n",
       "      <td>...</td>\n",
       "      <td>230924</td>\n",
       "      <td>231591</td>\n",
       "      <td>230924</td>\n",
       "      <td>20184579246637</td>\n",
       "      <td>378354</td>\n",
       "      <td>378354</td>\n",
       "      <td>378354</td>\n",
       "      <td>380190</td>\n",
       "      <td>378354</td>\n",
       "      <td>20184579246637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>325</td>\n",
       "      <td>192</td>\n",
       "      <td>109</td>\n",
       "      <td>24113</td>\n",
       "      <td>108</td>\n",
       "      <td>99</td>\n",
       "      <td>365473</td>\n",
       "      <td>365473</td>\n",
       "      <td>365473</td>\n",
       "      <td>367984</td>\n",
       "      <td>...</td>\n",
       "      <td>224310</td>\n",
       "      <td>224913</td>\n",
       "      <td>224310</td>\n",
       "      <td>21118563494803</td>\n",
       "      <td>298868</td>\n",
       "      <td>298868</td>\n",
       "      <td>298868</td>\n",
       "      <td>300226</td>\n",
       "      <td>298868</td>\n",
       "      <td>21118563494803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>238</td>\n",
       "      <td>202</td>\n",
       "      <td>88</td>\n",
       "      <td>84</td>\n",
       "      <td>24164</td>\n",
       "      <td>97</td>\n",
       "      <td>455803</td>\n",
       "      <td>455803</td>\n",
       "      <td>455803</td>\n",
       "      <td>459645</td>\n",
       "      <td>...</td>\n",
       "      <td>301940</td>\n",
       "      <td>303020</td>\n",
       "      <td>301940</td>\n",
       "      <td>20349561854881</td>\n",
       "      <td>227505</td>\n",
       "      <td>227505</td>\n",
       "      <td>227505</td>\n",
       "      <td>228744</td>\n",
       "      <td>227505</td>\n",
       "      <td>20349561854881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>44850</td>\n",
       "      <td>4169</td>\n",
       "      <td>4444</td>\n",
       "      <td>5995</td>\n",
       "      <td>12250</td>\n",
       "      <td>10429</td>\n",
       "      <td>7026166</td>\n",
       "      <td>7026166</td>\n",
       "      <td>7026166</td>\n",
       "      <td>7125421</td>\n",
       "      <td>...</td>\n",
       "      <td>9029669</td>\n",
       "      <td>9226329</td>\n",
       "      <td>9029669</td>\n",
       "      <td>25646792802733</td>\n",
       "      <td>4197832</td>\n",
       "      <td>4197832</td>\n",
       "      <td>4197832</td>\n",
       "      <td>4336094</td>\n",
       "      <td>4197832</td>\n",
       "      <td>25646792802733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>46233</td>\n",
       "      <td>6600</td>\n",
       "      <td>4695</td>\n",
       "      <td>5703</td>\n",
       "      <td>12648</td>\n",
       "      <td>10741</td>\n",
       "      <td>7061874</td>\n",
       "      <td>7061874</td>\n",
       "      <td>7061874</td>\n",
       "      <td>7151193</td>\n",
       "      <td>...</td>\n",
       "      <td>4082149</td>\n",
       "      <td>4143890</td>\n",
       "      <td>4082149</td>\n",
       "      <td>25361796963520</td>\n",
       "      <td>9375087</td>\n",
       "      <td>9375087</td>\n",
       "      <td>9375087</td>\n",
       "      <td>9637899</td>\n",
       "      <td>9375087</td>\n",
       "      <td>25361796963520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>47595</td>\n",
       "      <td>6722</td>\n",
       "      <td>7002</td>\n",
       "      <td>6275</td>\n",
       "      <td>7792</td>\n",
       "      <td>6486</td>\n",
       "      <td>7067191</td>\n",
       "      <td>7067191</td>\n",
       "      <td>7067191</td>\n",
       "      <td>7149621</td>\n",
       "      <td>...</td>\n",
       "      <td>3841004</td>\n",
       "      <td>3896173</td>\n",
       "      <td>3841004</td>\n",
       "      <td>25185773093257</td>\n",
       "      <td>5207676</td>\n",
       "      <td>5207676</td>\n",
       "      <td>5207676</td>\n",
       "      <td>5390828</td>\n",
       "      <td>5207676</td>\n",
       "      <td>25185773093257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>69171</td>\n",
       "      <td>6665</td>\n",
       "      <td>6167</td>\n",
       "      <td>29681</td>\n",
       "      <td>9059</td>\n",
       "      <td>8681</td>\n",
       "      <td>9022756</td>\n",
       "      <td>9022756</td>\n",
       "      <td>9022756</td>\n",
       "      <td>9169824</td>\n",
       "      <td>...</td>\n",
       "      <td>3172887</td>\n",
       "      <td>3248519</td>\n",
       "      <td>3172887</td>\n",
       "      <td>25938824596615</td>\n",
       "      <td>3668204</td>\n",
       "      <td>3668204</td>\n",
       "      <td>3668204</td>\n",
       "      <td>3826813</td>\n",
       "      <td>3668204</td>\n",
       "      <td>25938824596615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>48824</td>\n",
       "      <td>6581</td>\n",
       "      <td>4769</td>\n",
       "      <td>5597</td>\n",
       "      <td>7166</td>\n",
       "      <td>13052</td>\n",
       "      <td>7870006</td>\n",
       "      <td>7870006</td>\n",
       "      <td>7870006</td>\n",
       "      <td>7971618</td>\n",
       "      <td>...</td>\n",
       "      <td>3584685</td>\n",
       "      <td>3675423</td>\n",
       "      <td>3584685</td>\n",
       "      <td>26116774699384</td>\n",
       "      <td>4154373</td>\n",
       "      <td>4154373</td>\n",
       "      <td>4154373</td>\n",
       "      <td>4269576</td>\n",
       "      <td>4154373</td>\n",
       "      <td>26116774699384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4      5        6        7        8  \\\n",
       "0    24714    204     76     81     95     56  2012781  2012781  2012781   \n",
       "1      317  24612     91     77    102     70   367909   367909   367909   \n",
       "2      417    204  24127     82    121     87   375407   375407   375407   \n",
       "3      325    192    109  24113    108     99   365473   365473   365473   \n",
       "4      238    202     88     84  24164     97   455803   455803   455803   \n",
       "..     ...    ...    ...    ...    ...    ...      ...      ...      ...   \n",
       "199  44850   4169   4444   5995  12250  10429  7026166  7026166  7026166   \n",
       "200  46233   6600   4695   5703  12648  10741  7061874  7061874  7061874   \n",
       "201  47595   6722   7002   6275   7792   6486  7067191  7067191  7067191   \n",
       "202  69171   6665   6167  29681   9059   8681  9022756  9022756  9022756   \n",
       "203  48824   6581   4769   5597   7166  13052  7870006  7870006  7870006   \n",
       "\n",
       "           9  ...       86       87       88              89       90  \\\n",
       "0    2103291  ...   304791   305278   304791  20441615954968   229264   \n",
       "1     371353  ...   371333   372157   371333  20697549917815   225401   \n",
       "2     379037  ...   230924   231591   230924  20184579246637   378354   \n",
       "3     367984  ...   224310   224913   224310  21118563494803   298868   \n",
       "4     459645  ...   301940   303020   301940  20349561854881   227505   \n",
       "..       ...  ...      ...      ...      ...             ...      ...   \n",
       "199  7125421  ...  9029669  9226329  9029669  25646792802733  4197832   \n",
       "200  7151193  ...  4082149  4143890  4082149  25361796963520  9375087   \n",
       "201  7149621  ...  3841004  3896173  3841004  25185773093257  5207676   \n",
       "202  9169824  ...  3172887  3248519  3172887  25938824596615  3668204   \n",
       "203  7971618  ...  3584685  3675423  3584685  26116774699384  4154373   \n",
       "\n",
       "          91       92       93       94              95  \n",
       "0     229264   229264   230128   229264  20441615954968  \n",
       "1     225401   225401   226377   225401  20697549917815  \n",
       "2     378354   378354   380190   378354  20184579246637  \n",
       "3     298868   298868   300226   298868  21118563494803  \n",
       "4     227505   227505   228744   227505  20349561854881  \n",
       "..       ...      ...      ...      ...             ...  \n",
       "199  4197832  4197832  4336094  4197832  25646792802733  \n",
       "200  9375087  9375087  9637899  9375087  25361796963520  \n",
       "201  5207676  5207676  5390828  5207676  25185773093257  \n",
       "202  3668204  3668204  3826813  3668204  25938824596615  \n",
       "203  4154373  4154373  4269576  4154373  26116774699384  \n",
       "\n",
       "[204 rows x 96 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(columns=['labels']).copy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "collapsed": true,
    "id": "NLuFDRCzeBHa",
    "outputId": "05fa9ff8-371a-4470-b6bd-ef2c62182d4c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24726.275794</td>\n",
       "      <td>203.971794</td>\n",
       "      <td>76.049224</td>\n",
       "      <td>81.123365</td>\n",
       "      <td>94.977755</td>\n",
       "      <td>55.986888</td>\n",
       "      <td>2.015960e+06</td>\n",
       "      <td>2.014326e+06</td>\n",
       "      <td>2.011836e+06</td>\n",
       "      <td>2.104432e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.050700e+05</td>\n",
       "      <td>3.053784e+05</td>\n",
       "      <td>3.046295e+05</td>\n",
       "      <td>2.045211e+13</td>\n",
       "      <td>2.292863e+05</td>\n",
       "      <td>2.294861e+05</td>\n",
       "      <td>2.291030e+05</td>\n",
       "      <td>2.300526e+05</td>\n",
       "      <td>2.291741e+05</td>\n",
       "      <td>2.041170e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>317.093870</td>\n",
       "      <td>24618.425092</td>\n",
       "      <td>91.000465</td>\n",
       "      <td>76.981937</td>\n",
       "      <td>101.855632</td>\n",
       "      <td>69.970555</td>\n",
       "      <td>3.677829e+05</td>\n",
       "      <td>3.676138e+05</td>\n",
       "      <td>3.678497e+05</td>\n",
       "      <td>3.715030e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.709353e+05</td>\n",
       "      <td>3.723366e+05</td>\n",
       "      <td>3.712500e+05</td>\n",
       "      <td>2.071233e+13</td>\n",
       "      <td>2.255077e+05</td>\n",
       "      <td>2.253846e+05</td>\n",
       "      <td>2.252101e+05</td>\n",
       "      <td>2.260341e+05</td>\n",
       "      <td>2.253004e+05</td>\n",
       "      <td>2.071528e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>417.089277</td>\n",
       "      <td>203.745869</td>\n",
       "      <td>24131.178336</td>\n",
       "      <td>82.031596</td>\n",
       "      <td>120.893053</td>\n",
       "      <td>87.013374</td>\n",
       "      <td>3.754289e+05</td>\n",
       "      <td>3.749779e+05</td>\n",
       "      <td>3.755413e+05</td>\n",
       "      <td>3.792496e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.309401e+05</td>\n",
       "      <td>2.315018e+05</td>\n",
       "      <td>2.309502e+05</td>\n",
       "      <td>2.019794e+13</td>\n",
       "      <td>3.789541e+05</td>\n",
       "      <td>3.778857e+05</td>\n",
       "      <td>3.791610e+05</td>\n",
       "      <td>3.794478e+05</td>\n",
       "      <td>3.782966e+05</td>\n",
       "      <td>2.019645e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>325.091322</td>\n",
       "      <td>191.880442</td>\n",
       "      <td>108.977315</td>\n",
       "      <td>24101.112268</td>\n",
       "      <td>107.936349</td>\n",
       "      <td>99.084111</td>\n",
       "      <td>3.656035e+05</td>\n",
       "      <td>3.652198e+05</td>\n",
       "      <td>3.658018e+05</td>\n",
       "      <td>3.680971e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.247930e+05</td>\n",
       "      <td>2.247404e+05</td>\n",
       "      <td>2.245057e+05</td>\n",
       "      <td>2.112244e+13</td>\n",
       "      <td>2.995225e+05</td>\n",
       "      <td>2.986264e+05</td>\n",
       "      <td>2.986170e+05</td>\n",
       "      <td>3.000460e+05</td>\n",
       "      <td>2.982332e+05</td>\n",
       "      <td>2.110746e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237.819326</td>\n",
       "      <td>202.030380</td>\n",
       "      <td>88.030075</td>\n",
       "      <td>84.157598</td>\n",
       "      <td>24186.966042</td>\n",
       "      <td>96.944040</td>\n",
       "      <td>4.553935e+05</td>\n",
       "      <td>4.560272e+05</td>\n",
       "      <td>4.552012e+05</td>\n",
       "      <td>4.604868e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.018570e+05</td>\n",
       "      <td>3.023225e+05</td>\n",
       "      <td>3.014825e+05</td>\n",
       "      <td>2.037738e+13</td>\n",
       "      <td>2.278792e+05</td>\n",
       "      <td>2.274483e+05</td>\n",
       "      <td>2.276362e+05</td>\n",
       "      <td>2.288152e+05</td>\n",
       "      <td>2.282055e+05</td>\n",
       "      <td>2.037234e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>44820.794743</td>\n",
       "      <td>4170.009916</td>\n",
       "      <td>4435.610340</td>\n",
       "      <td>5999.211506</td>\n",
       "      <td>12273.944616</td>\n",
       "      <td>10416.021776</td>\n",
       "      <td>7.025524e+06</td>\n",
       "      <td>7.032352e+06</td>\n",
       "      <td>7.026387e+06</td>\n",
       "      <td>7.126597e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>9.036767e+06</td>\n",
       "      <td>9.242914e+06</td>\n",
       "      <td>9.025481e+06</td>\n",
       "      <td>2.565718e+13</td>\n",
       "      <td>4.193763e+06</td>\n",
       "      <td>4.201375e+06</td>\n",
       "      <td>4.201606e+06</td>\n",
       "      <td>4.346488e+06</td>\n",
       "      <td>4.199856e+06</td>\n",
       "      <td>2.566536e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>46211.232099</td>\n",
       "      <td>6603.573104</td>\n",
       "      <td>4693.216411</td>\n",
       "      <td>5703.660754</td>\n",
       "      <td>12650.207274</td>\n",
       "      <td>10737.215893</td>\n",
       "      <td>7.062319e+06</td>\n",
       "      <td>7.059224e+06</td>\n",
       "      <td>7.059192e+06</td>\n",
       "      <td>7.158892e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.081618e+06</td>\n",
       "      <td>4.147575e+06</td>\n",
       "      <td>4.085538e+06</td>\n",
       "      <td>2.537679e+13</td>\n",
       "      <td>9.351406e+06</td>\n",
       "      <td>9.376287e+06</td>\n",
       "      <td>9.374066e+06</td>\n",
       "      <td>9.639518e+06</td>\n",
       "      <td>9.368015e+06</td>\n",
       "      <td>2.532820e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>47617.043076</td>\n",
       "      <td>6719.604943</td>\n",
       "      <td>7006.024000</td>\n",
       "      <td>6270.790012</td>\n",
       "      <td>7803.032776</td>\n",
       "      <td>6492.492907</td>\n",
       "      <td>7.069289e+06</td>\n",
       "      <td>7.065684e+06</td>\n",
       "      <td>7.073215e+06</td>\n",
       "      <td>7.152428e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.840574e+06</td>\n",
       "      <td>3.899878e+06</td>\n",
       "      <td>3.844841e+06</td>\n",
       "      <td>2.511244e+13</td>\n",
       "      <td>5.211025e+06</td>\n",
       "      <td>5.207822e+06</td>\n",
       "      <td>5.200848e+06</td>\n",
       "      <td>5.395573e+06</td>\n",
       "      <td>5.219373e+06</td>\n",
       "      <td>2.519980e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>69247.117736</td>\n",
       "      <td>6677.024454</td>\n",
       "      <td>6161.879773</td>\n",
       "      <td>29625.865422</td>\n",
       "      <td>9064.950550</td>\n",
       "      <td>8678.850484</td>\n",
       "      <td>9.010357e+06</td>\n",
       "      <td>9.022051e+06</td>\n",
       "      <td>9.029320e+06</td>\n",
       "      <td>9.168458e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.172087e+06</td>\n",
       "      <td>3.248590e+06</td>\n",
       "      <td>3.167049e+06</td>\n",
       "      <td>2.593192e+13</td>\n",
       "      <td>3.659086e+06</td>\n",
       "      <td>3.666056e+06</td>\n",
       "      <td>3.671341e+06</td>\n",
       "      <td>3.828525e+06</td>\n",
       "      <td>3.666022e+06</td>\n",
       "      <td>2.593988e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>48771.514709</td>\n",
       "      <td>6580.984578</td>\n",
       "      <td>4782.974697</td>\n",
       "      <td>5607.330950</td>\n",
       "      <td>7166.377090</td>\n",
       "      <td>13054.090202</td>\n",
       "      <td>7.862297e+06</td>\n",
       "      <td>7.863696e+06</td>\n",
       "      <td>7.872856e+06</td>\n",
       "      <td>7.967434e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.581942e+06</td>\n",
       "      <td>3.676990e+06</td>\n",
       "      <td>3.588957e+06</td>\n",
       "      <td>2.613521e+13</td>\n",
       "      <td>4.158246e+06</td>\n",
       "      <td>4.155087e+06</td>\n",
       "      <td>4.150484e+06</td>\n",
       "      <td>4.266119e+06</td>\n",
       "      <td>4.155702e+06</td>\n",
       "      <td>2.614140e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4  \\\n",
       "0    24726.275794    203.971794     76.049224     81.123365     94.977755   \n",
       "1      317.093870  24618.425092     91.000465     76.981937    101.855632   \n",
       "2      417.089277    203.745869  24131.178336     82.031596    120.893053   \n",
       "3      325.091322    191.880442    108.977315  24101.112268    107.936349   \n",
       "4      237.819326    202.030380     88.030075     84.157598  24186.966042   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "199  44820.794743   4170.009916   4435.610340   5999.211506  12273.944616   \n",
       "200  46211.232099   6603.573104   4693.216411   5703.660754  12650.207274   \n",
       "201  47617.043076   6719.604943   7006.024000   6270.790012   7803.032776   \n",
       "202  69247.117736   6677.024454   6161.879773  29625.865422   9064.950550   \n",
       "203  48771.514709   6580.984578   4782.974697   5607.330950   7166.377090   \n",
       "\n",
       "                5             6             7             8             9  \\\n",
       "0       55.986888  2.015960e+06  2.014326e+06  2.011836e+06  2.104432e+06   \n",
       "1       69.970555  3.677829e+05  3.676138e+05  3.678497e+05  3.715030e+05   \n",
       "2       87.013374  3.754289e+05  3.749779e+05  3.755413e+05  3.792496e+05   \n",
       "3       99.084111  3.656035e+05  3.652198e+05  3.658018e+05  3.680971e+05   \n",
       "4       96.944040  4.553935e+05  4.560272e+05  4.552012e+05  4.604868e+05   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "199  10416.021776  7.025524e+06  7.032352e+06  7.026387e+06  7.126597e+06   \n",
       "200  10737.215893  7.062319e+06  7.059224e+06  7.059192e+06  7.158892e+06   \n",
       "201   6492.492907  7.069289e+06  7.065684e+06  7.073215e+06  7.152428e+06   \n",
       "202   8678.850484  9.010357e+06  9.022051e+06  9.029320e+06  9.168458e+06   \n",
       "203  13054.090202  7.862297e+06  7.863696e+06  7.872856e+06  7.967434e+06   \n",
       "\n",
       "     ...            86            87            88            89  \\\n",
       "0    ...  3.050700e+05  3.053784e+05  3.046295e+05  2.045211e+13   \n",
       "1    ...  3.709353e+05  3.723366e+05  3.712500e+05  2.071233e+13   \n",
       "2    ...  2.309401e+05  2.315018e+05  2.309502e+05  2.019794e+13   \n",
       "3    ...  2.247930e+05  2.247404e+05  2.245057e+05  2.112244e+13   \n",
       "4    ...  3.018570e+05  3.023225e+05  3.014825e+05  2.037738e+13   \n",
       "..   ...           ...           ...           ...           ...   \n",
       "199  ...  9.036767e+06  9.242914e+06  9.025481e+06  2.565718e+13   \n",
       "200  ...  4.081618e+06  4.147575e+06  4.085538e+06  2.537679e+13   \n",
       "201  ...  3.840574e+06  3.899878e+06  3.844841e+06  2.511244e+13   \n",
       "202  ...  3.172087e+06  3.248590e+06  3.167049e+06  2.593192e+13   \n",
       "203  ...  3.581942e+06  3.676990e+06  3.588957e+06  2.613521e+13   \n",
       "\n",
       "               90            91            92            93            94  \\\n",
       "0    2.292863e+05  2.294861e+05  2.291030e+05  2.300526e+05  2.291741e+05   \n",
       "1    2.255077e+05  2.253846e+05  2.252101e+05  2.260341e+05  2.253004e+05   \n",
       "2    3.789541e+05  3.778857e+05  3.791610e+05  3.794478e+05  3.782966e+05   \n",
       "3    2.995225e+05  2.986264e+05  2.986170e+05  3.000460e+05  2.982332e+05   \n",
       "4    2.278792e+05  2.274483e+05  2.276362e+05  2.288152e+05  2.282055e+05   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "199  4.193763e+06  4.201375e+06  4.201606e+06  4.346488e+06  4.199856e+06   \n",
       "200  9.351406e+06  9.376287e+06  9.374066e+06  9.639518e+06  9.368015e+06   \n",
       "201  5.211025e+06  5.207822e+06  5.200848e+06  5.395573e+06  5.219373e+06   \n",
       "202  3.659086e+06  3.666056e+06  3.671341e+06  3.828525e+06  3.666022e+06   \n",
       "203  4.158246e+06  4.155087e+06  4.150484e+06  4.266119e+06  4.155702e+06   \n",
       "\n",
       "               95  \n",
       "0    2.041170e+13  \n",
       "1    2.071528e+13  \n",
       "2    2.019645e+13  \n",
       "3    2.110746e+13  \n",
       "4    2.037234e+13  \n",
       "..            ...  \n",
       "199  2.566536e+13  \n",
       "200  2.532820e+13  \n",
       "201  2.519980e+13  \n",
       "202  2.593988e+13  \n",
       "203  2.614140e+13  \n",
       "\n",
       "[204 rows x 96 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "noise = 0.001 * np.random.randn(*data.shape) * data\n",
    "data_noisy = data + noise\n",
    "data_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9dmH9YhSsTi",
    "outputId": "db0a34fc-330f-4efd-c55e-d5b6534903ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: Linear, Accuracy: 0.69\n",
      "Kernel: Poly, Accuracy: 0.83\n",
      "Kernel: Rbf, Accuracy: 0.88\n",
      "Kernel: Sigmoid, Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(42)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(data_noisy)\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "    oc_svm = OneClassSVM(kernel=kernel, gamma='auto', nu=0.1)\n",
    "    oc_svm.fit(X_scaled)\n",
    "    pseudo_labels = oc_svm.predict(X_scaled)\n",
    "    accuracy = np.mean(pseudo_labels == 1)\n",
    "    print(f'Kernel: {kernel.capitalize()}, Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "vzWyiVi4i5Li",
    "outputId": "fbf157cb-bc8b-43f0-abd7-7024ff8b1fbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pandas as pd\\nimport numpy as np\\nfrom sklearn.svm import SVC\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.pipeline import make_pipeline\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.model_selection import cross_val_score\\n\\nnp.random.seed(42)\\ndf_noisy = pd.DataFrame(np.random.rand(204, 96) * 1e6)\\nscaler = StandardScaler()\\nX_scaled = scaler.fit_transform(df_noisy)\\nkmeans = KMeans(n_clusters= 2 , random_state=42)\\npseudo_labels = kmeans.fit_predict(X_scaled)\\n\\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, pseudo_labels, test_size=0.2, random_state=42)\\nkernels = ['linear', 'poly', 'rbf', 'sigmoid']\\n\\nfor kernel in kernels:\\n    svc = make_pipeline(StandardScaler(), SVC(kernel=kernel, random_state=42))\\n    svc.fit(X_train, y_train)\\n    y_pred = svc.predict(X_test)\\n    accuracy = accuracy_score(y_test, y_pred)\\n    print(f'Kernel: {kernel}, Accuracy: {accuracy:.2f}')\\nsvc_precomputed = SVC(kernel='precomputed', random_state=42)\\n\\ngram_matrix_train = np.dot(X_train, X_train.T)\\ngram_matrix_test = np.dot(X_test, X_train.T)\\n\\nsvc_precomputed.fit(gram_matrix_train, y_train)\\ny_pred_precomputed = svc_precomputed.predict(gram_matrix_test)\\naccuracy_precomputed = accuracy_score(y_test, y_pred_precomputed)\\nprint(f'Kernel: precomputed (linear), Accuracy: {accuracy_precomputed:.2f}')\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "np.random.seed(42)\n",
    "df_noisy = pd.DataFrame(np.random.rand(204, 96) * 1e6)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_noisy)\n",
    "kmeans = KMeans(n_clusters= 2 , random_state=42)\n",
    "pseudo_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, pseudo_labels, test_size=0.2, random_state=42)\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    svc = make_pipeline(StandardScaler(), SVC(kernel=kernel, random_state=42))\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Kernel: {kernel}, Accuracy: {accuracy:.2f}')\n",
    "svc_precomputed = SVC(kernel='precomputed', random_state=42)\n",
    "\n",
    "gram_matrix_train = np.dot(X_train, X_train.T)\n",
    "gram_matrix_test = np.dot(X_test, X_train.T)\n",
    "\n",
    "svc_precomputed.fit(gram_matrix_train, y_train)\n",
    "y_pred_precomputed = svc_precomputed.predict(gram_matrix_test)\n",
    "accuracy_precomputed = accuracy_score(y_test, y_pred_precomputed)\n",
    "print(f'Kernel: precomputed (linear), Accuracy: {accuracy_precomputed:.2f}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlKBFCPCCZOb",
    "outputId": "eaef8503-edc1-478e-f473-596321c37cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: Linear, Accuracy: 0.56\n",
      "Kernel: Poly, Accuracy: 0.09\n",
      "Kernel: Rbf, Accuracy: 0.08\n",
      "Kernel: Sigmoid, Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(42)\n",
    "scaler = StandardScaler()\n",
    "train_data = data_noisy[:22]\n",
    "test_data = data_noisy[:204]\n",
    "X_train_scaled = scaler.fit_transform(train_data)\n",
    "X_test_scaled = scaler.transform(test_data)\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "    oc_svm = OneClassSVM(kernel=kernel, gamma='auto', nu=0.1)\n",
    "    oc_svm.fit(X_train_scaled)\n",
    "    pseudo_labels = oc_svm.predict(X_test_scaled)\n",
    "    accuracy = np.mean(pseudo_labels == 1)\n",
    "    print(f'Kernel: {kernel.capitalize()}, Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PIlUhKmzWKo",
    "outputId": "f5fd82ec-2ea7-4b98-c2c3-1860c6325c37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------------+--------------------+----------------+--------------------+-----------------+-------------------+------------------+---------------+-----------------+-----------------+--------------+----------------+---------------------+------------------+--------------------+\n",
      "| Application   |   Linear Accuracy |   Poly Accuracy |   Sigmoid Accuracy |   RBF Accuracy |   Linear Precision |   Linear Recall |   Linear F1-score |   Poly Precision |   Poly Recall |   Poly F1-score |   RBF Precision |   RBF Recall |   RBF F1-score |   Sigmoid Precision |   Sigmoid Recall |   Sigmoid F1-score |\n",
      "+===============+===================+=================+====================+================+====================+=================+===================+==================+===============+=================+=================+==============+================+=====================+==================+====================+\n",
      "| Blackscholes  |                 1 |            0.5  |               0.67 |           0.5  |                  1 |            0.41 |              0.58 |             0.41 |             1 |            0.77 |            0.87 |         0.77 |              1 |                0.82 |             0.9  |               0.82 |\n",
      "+---------------+-------------------+-----------------+--------------------+----------------+--------------------+-----------------+-------------------+------------------+---------------+-----------------+-----------------+--------------+----------------+---------------------+------------------+--------------------+\n",
      "| Bodytrack     |                 1 |            0.61 |               0.76 |           0.61 |                  1 |            0.33 |              0.5  |             0.33 |             1 |            0.61 |            0.76 |         0.61 |              1 |                0.67 |             0.8  |               0.67 |\n",
      "+---------------+-------------------+-----------------+--------------------+----------------+--------------------+-----------------+-------------------+------------------+---------------+-----------------+-----------------+--------------+----------------+---------------------+------------------+--------------------+\n",
      "| Canneal       |                 1 |            0.61 |               0.76 |           0.61 |                  1 |            0.33 |              0.5  |             0.33 |             1 |            0.61 |            0.76 |         0.61 |              1 |                0.67 |             0.8  |               0.67 |\n",
      "+---------------+-------------------+-----------------+--------------------+----------------+--------------------+-----------------+-------------------+------------------+---------------+-----------------+-----------------+--------------+----------------+---------------------+------------------+--------------------+\n",
      "| X264          |                 1 |            0.65 |               0.79 |           0.65 |                  1 |            0.47 |              0.64 |             0.47 |             1 |            0.47 |            0.64 |         0.47 |              1 |                0.76 |             0.87 |               0.76 |\n",
      "+---------------+-------------------+-----------------+--------------------+----------------+--------------------+-----------------+-------------------+------------------+---------------+-----------------+-----------------+--------------+----------------+---------------------+------------------+--------------------+\n",
      "| Dedup         |                 1 |            0.44 |               0.61 |           0.44 |                  1 |            0.44 |              0.61 |             0.44 |             1 |            0.69 |            0.81 |         0.69 |              1 |                0.62 |             0.77 |               0.62 |\n",
      "+---------------+-------------------+-----------------+--------------------+----------------+--------------------+-----------------+-------------------+------------------+---------------+-----------------+-----------------+--------------+----------------+---------------------+------------------+--------------------+\n",
      "| Ferret        |                 1 |            0.44 |               0.61 |           0.44 |                  1 |            0.44 |              0.61 |             0.44 |             1 |            0.69 |            0.81 |         0.69 |              1 |                0.62 |             0.77 |               0.62 |\n",
      "+---------------+-------------------+-----------------+--------------------+----------------+--------------------+-----------------+-------------------+------------------+---------------+-----------------+-----------------+--------------+----------------+---------------------+------------------+--------------------+\n",
      "| Fluidanimate  |                 1 |            0.44 |               0.61 |           0.44 |                  1 |            0.44 |              0.61 |             0.44 |             1 |            0.69 |            0.81 |         0.69 |              1 |                0.62 |             0.77 |               0.62 |\n",
      "+---------------+-------------------+-----------------+--------------------+----------------+--------------------+-----------------+-------------------+------------------+---------------+-----------------+-----------------+--------------+----------------+---------------------+------------------+--------------------+\n",
      "| Raytrace      |                 1 |            0.44 |               0.61 |           0.44 |                  1 |            0.44 |              0.61 |             0.44 |             1 |            0.69 |            0.81 |         0.69 |              1 |                0.62 |             0.77 |               0.62 |\n",
      "+---------------+-------------------+-----------------+--------------------+----------------+--------------------+-----------------+-------------------+------------------+---------------+-----------------+-----------------+--------------+----------------+---------------------+------------------+--------------------+\n",
      "| Streamcluster |                 1 |            0.44 |               0.61 |           0.44 |                  1 |            0.44 |              0.61 |             0.44 |             1 |            0.69 |            0.81 |         0.69 |              1 |                0.62 |             0.77 |               0.62 |\n",
      "+---------------+-------------------+-----------------+--------------------+----------------+--------------------+-----------------+-------------------+------------------+---------------+-----------------+-----------------+--------------+----------------+---------------------+------------------+--------------------+\n",
      "| Swaptions     |                 1 |            0.44 |               0.61 |           0.44 |                  1 |            0.44 |              0.61 |             0.44 |             1 |            0.69 |            0.81 |         0.69 |              1 |                0.62 |             0.77 |               0.62 |\n",
      "+---------------+-------------------+-----------------+--------------------+----------------+--------------------+-----------------+-------------------+------------------+---------------+-----------------+-----------------+--------------+----------------+---------------------+------------------+--------------------+\n",
      "| Vips          |                 1 |            0.44 |               0.61 |           0.44 |                  1 |            0.44 |              0.61 |             0.44 |             1 |            0.69 |            0.81 |         0.69 |              1 |                0.62 |             0.77 |               0.62 |\n",
      "+---------------+-------------------+-----------------+--------------------+----------------+--------------------+-----------------+-------------------+------------------+---------------+-----------------+-----------------+--------------+----------------+---------------------+------------------+--------------------+\n",
      "| Freqmine      |                 1 |            0.53 |               0.7  |           0.53 |                  1 |            0.53 |              0.7  |             0.53 |             1 |            0.4  |            0.57 |         0.4  |              1 |                0.67 |             0.8  |               0.67 |\n",
      "+---------------+-------------------+-----------------+--------------------+----------------+--------------------+-----------------+-------------------+------------------+---------------+-----------------+-----------------+--------------+----------------+---------------------+------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "np.random.seed(42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "applications = {\n",
    "    'blackscholes': 22,\n",
    "    'bodytrack': 18,\n",
    "    'canneal': 18,\n",
    "    'x264': 17,\n",
    "    'dedup': 16,\n",
    "    'ferret': 16,\n",
    "    'fluidanimate': 16,\n",
    "    'raytrace': 16,\n",
    "    'streamcluster': 16,\n",
    "    'swaptions': 16,\n",
    "    'vips': 16,\n",
    "    'freqmine': 15\n",
    "}\n",
    "\n",
    "results = {app.capitalize(): {kernel.capitalize(): {'Precision': 0, 'Recall': 0, 'F1-score': 0, 'Accuracy': 0} for kernel in ['linear', 'poly', 'rbf', 'sigmoid']} for app in applications}\n",
    "for app, rows in applications.items():\n",
    "    subset_data = data_noisy[:rows]\n",
    "    X_scaled = scaler.fit_transform(subset_data)\n",
    "\n",
    "    kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    for kernel in kernels:\n",
    "        oc_svm = OneClassSVM(kernel=kernel, gamma='auto', nu=0.1)\n",
    "        oc_svm.fit(X_scaled)\n",
    "        pseudo_labels = oc_svm.predict(X_scaled)\n",
    "        precision = precision_score(np.ones(rows), pseudo_labels == 1)\n",
    "        recall = recall_score(np.ones(rows), pseudo_labels == 1)\n",
    "        f1 = f1_score(np.ones(rows), pseudo_labels == 1)\n",
    "        accuracy = accuracy_score(np.ones(rows), pseudo_labels == 1)\n",
    "\n",
    "        results[app.capitalize()][kernel.capitalize()] = {\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-score': f1,\n",
    "            'Accuracy': accuracy\n",
    "        }\n",
    "tabulate_data = []\n",
    "for app, kernels_data in results.items():\n",
    "    row = [app]\n",
    "    for kernel in kernels:\n",
    "        scores = kernels_data[kernel.capitalize()]\n",
    "        row.extend([f'{scores[\"Precision\"]:.2f}', f'{scores[\"Recall\"]:.2f}', f'{scores[\"F1-score\"]:.2f}', f'{scores[\"Accuracy\"]:.2f}'])\n",
    "    tabulate_data.append(row)\n",
    "headers = ['Application',  'Linear Accuracy', 'Poly Accuracy', 'Sigmoid Accuracy', 'RBF Accuracy', 'Linear Precision', 'Linear Recall', 'Linear F1-score',\n",
    "           'Poly Precision', 'Poly Recall', 'Poly F1-score',\n",
    "           'RBF Precision', 'RBF Recall', 'RBF F1-score',\n",
    "           'Sigmoid Precision', 'Sigmoid Recall', 'Sigmoid F1-score']\n",
    "print(tabulate(tabulate_data, headers=headers, tablefmt='grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fhUGneXK5yQ",
    "outputId": "da3612a0-173e-4454-dfff-74ec00c6554d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+---------------------+------------------+--------------------+\n",
      "| Application   |   Sigmoid Accuracy |   Sigmoid Precision |   Sigmoid Recall |   Sigmoid F1-score |\n",
      "+===============+====================+=====================+==================+====================+\n",
      "| Blackscholes  |               0.91 |                   1 |             0.91 |               0.95 |\n",
      "+---------------+--------------------+---------------------+------------------+--------------------+\n",
      "| Bodytrack     |               0.94 |                   1 |             0.94 |               0.97 |\n",
      "+---------------+--------------------+---------------------+------------------+--------------------+\n",
      "| Canneal       |               0.94 |                   1 |             0.94 |               0.97 |\n",
      "+---------------+--------------------+---------------------+------------------+--------------------+\n",
      "| X264          |               0.88 |                   1 |             0.88 |               0.94 |\n",
      "+---------------+--------------------+---------------------+------------------+--------------------+\n",
      "| Dedup         |               0.81 |                   1 |             0.81 |               0.9  |\n",
      "+---------------+--------------------+---------------------+------------------+--------------------+\n",
      "| Ferret        |               0.81 |                   1 |             0.81 |               0.9  |\n",
      "+---------------+--------------------+---------------------+------------------+--------------------+\n",
      "| Fluidanimate  |               0.81 |                   1 |             0.81 |               0.9  |\n",
      "+---------------+--------------------+---------------------+------------------+--------------------+\n",
      "| Raytrace      |               0.81 |                   1 |             0.81 |               0.9  |\n",
      "+---------------+--------------------+---------------------+------------------+--------------------+\n",
      "| Streamcluster |               0.81 |                   1 |             0.81 |               0.9  |\n",
      "+---------------+--------------------+---------------------+------------------+--------------------+\n",
      "| Swaptions     |               0.81 |                   1 |             0.81 |               0.9  |\n",
      "+---------------+--------------------+---------------------+------------------+--------------------+\n",
      "| Vips          |               0.81 |                   1 |             0.81 |               0.9  |\n",
      "+---------------+--------------------+---------------------+------------------+--------------------+\n",
      "| Freqmine      |               0.87 |                   1 |             0.87 |               0.93 |\n",
      "+---------------+--------------------+---------------------+------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Assuming data_noisy is a pre-defined DataFrame\n",
    "np.random.seed(42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "applications = {\n",
    "    'blackscholes': 22,\n",
    "    'bodytrack': 18,\n",
    "    'canneal': 18,\n",
    "    'x264': 17,\n",
    "    'dedup': 16,\n",
    "    'ferret': 16,\n",
    "    'fluidanimate': 16,\n",
    "    'raytrace': 16,\n",
    "    'streamcluster': 16,\n",
    "    'swaptions': 16,\n",
    "    'vips': 16,\n",
    "    'freqmine': 15\n",
    "}\n",
    "sigmoid_params = {\n",
    "    'gamma': 0.1 ,\n",
    "    'nu': 0.05\n",
    "}\n",
    "results = {app.capitalize(): {kernel.capitalize(): {'Precision': 0, 'Recall': 0, 'F1-score': 0, 'Accuracy': 0} for kernel in ['linear', 'poly', 'rbf', 'sigmoid']} for app in applications}\n",
    "for app, rows in applications.items():\n",
    "    subset_data = data_noisy[:rows]\n",
    "    X_scaled = scaler.fit_transform(subset_data)\n",
    "\n",
    "    kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    for kernel in kernels:\n",
    "        if kernel == 'sigmoid':\n",
    "            oc_svm = OneClassSVM(kernel=kernel, gamma=sigmoid_params['gamma'], nu=sigmoid_params['nu'])\n",
    "        else:\n",
    "            oc_svm = OneClassSVM(kernel=kernel, gamma='auto', nu=0.1)\n",
    "\n",
    "        oc_svm.fit(X_scaled)\n",
    "        pseudo_labels = oc_svm.predict(X_scaled)\n",
    "        precision = precision_score(np.ones(rows), pseudo_labels == 1)\n",
    "        recall = recall_score(np.ones(rows), pseudo_labels == 1)\n",
    "        f1 = f1_score(np.ones(rows), pseudo_labels == 1)\n",
    "        accuracy = accuracy_score(np.ones(rows), pseudo_labels == 1)\n",
    "\n",
    "        results[app.capitalize()][kernel.capitalize()] = {\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-score': f1,\n",
    "            'Accuracy': accuracy\n",
    "        }\n",
    "tabulate_data = []\n",
    "for app, kernels_data in results.items():\n",
    "    sigmoid_data = kernels_data['Sigmoid']\n",
    "    row = [app, f'{sigmoid_data[\"Accuracy\"]:.2f}', f'{sigmoid_data[\"Precision\"]:.2f}', f'{sigmoid_data[\"Recall\"]:.2f}', f'{sigmoid_data[\"F1-score\"]:.2f}']\n",
    "    tabulate_data.append(row)\n",
    "headers = ['Application', 'Sigmoid Accuracy', 'Sigmoid Precision', 'Sigmoid Recall', 'Sigmoid F1-score']\n",
    "print(tabulate(tabulate_data, headers=headers, tablefmt='grid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7-6OONFkWT3",
    "outputId": "e59306fa-7c6a-468a-c90c-6ecc015c28ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: Linear, Accuracy: 0.58\n",
      "Kernel: Poly, Accuracy: 0.33\n",
      "Kernel: Rbf, Accuracy: 0.25\n",
      "Kernel: Sigmoid, Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Assuming data_noisy is your dataset\n",
    "train_data = data_noisy[::13]  # Selecting alternate 10 rows\n",
    "test_data = data_noisy[:204]\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(train_data)\n",
    "X_test_scaled = scaler.transform(test_data)\n",
    "\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "    oc_svm = OneClassSVM(kernel=kernel, gamma='auto', nu=0.1)\n",
    "    oc_svm.fit(X_train_scaled)\n",
    "    pseudo_labels = oc_svm.predict(X_test_scaled)\n",
    "    accuracy = np.mean(pseudo_labels == 1)\n",
    "    print(f'Kernel: {kernel.capitalize()}, Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Application   |   QSVM Accuracy |   QSVM Precision |   QSVM Recall |   QSVM F1-score |\n",
      "+===============+=================+==================+===============+=================+\n",
      "| Blackscholes  |            0.64 |                1 |          0.64 |            0.78 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Bodytrack     |            0.72 |                1 |          0.72 |            0.84 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Canneal       |            0.72 |                1 |          0.72 |            0.84 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| X264          |            0.76 |                1 |          0.76 |            0.87 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Dedup         |            0.69 |                1 |          0.69 |            0.81 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Ferret        |            0.69 |                1 |          0.69 |            0.81 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Fluidanimate  |            0.69 |                1 |          0.69 |            0.81 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Raytrace      |            0.69 |                1 |          0.69 |            0.81 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Streamcluster |            0.69 |                1 |          0.69 |            0.81 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Swaptions     |            0.69 |                1 |          0.69 |            0.81 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Vips          |            0.69 |                1 |          0.69 |            0.81 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Freqmine      |            0.53 |                1 |          0.53 |            0.7  |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA  \n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit_aer import AerSimulator\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "data_noisy_reduced = pca.fit_transform(data_noisy)\n",
    "data_noisy = pd.DataFrame(data_noisy_reduced)\n",
    "\n",
    "applications = {\n",
    "    'blackscholes': 22,\n",
    "    'bodytrack': 18,\n",
    "    'canneal': 18,\n",
    "    'x264': 17,\n",
    "    'dedup': 16,\n",
    "    'ferret': 16,\n",
    "    'fluidanimate': 16,\n",
    "    'raytrace': 16,\n",
    "    'streamcluster': 16,\n",
    "    'swaptions': 16,\n",
    "    'vips': 16,\n",
    "    'freqmine': 15\n",
    "}\n",
    "\n",
    "num_features = data_noisy.shape[1]\n",
    "\n",
    "max_qubits = 10\n",
    "if num_features > max_qubits:\n",
    "    num_features = max_qubits\n",
    "    # Use .iloc for pandas DataFrame\n",
    "    data_noisy = data_noisy.iloc[:, :num_features]\n",
    "    # Alternatively, if you prefer numpy arrays:\n",
    "    # data_noisy = data_noisy.values\n",
    "    # data_noisy = data_noisy[:, :num_features]\n",
    "\n",
    "results = {\n",
    "    app.capitalize(): {\n",
    "        'QSVM': {'Precision': 0, 'Recall': 0, 'F1-score': 0, 'Accuracy': 0}\n",
    "    } for app in applications\n",
    "}\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2, entanglement='linear')\n",
    "\n",
    "backend = AerSimulator(method='statevector')\n",
    "\n",
    "def compute_kernel_matrix(X, Y):\n",
    "    # Create quantum circuits for each data point\n",
    "    circuits_X = [feature_map.assign_parameters(x, inplace=False) for x in X]\n",
    "    circuits_Y = [feature_map.assign_parameters(y, inplace=False) for y in Y]\n",
    "    \n",
    "    statevectors_X = [Statevector.from_instruction(circ).data for circ in circuits_X]\n",
    "    statevectors_Y = [Statevector.from_instruction(circ).data for circ in circuits_Y]\n",
    "    \n",
    "    kernel_matrix = np.zeros((len(X), len(Y)))\n",
    "    \n",
    "    for i, state_x in enumerate(statevectors_X):\n",
    "        for j, state_y in enumerate(statevectors_Y):\n",
    "            fidelity = np.abs(np.vdot(state_x, state_y))**2\n",
    "            kernel_matrix[i, j] = fidelity\n",
    "    \n",
    "    return kernel_matrix\n",
    "\n",
    "for app, rows in applications.items():\n",
    "    subset_data = data_noisy.iloc[:rows]  # Use .iloc if data_noisy is a DataFrame\n",
    "    X_scaled = scaler.fit_transform(subset_data)\n",
    "    \n",
    "    K = compute_kernel_matrix(X_scaled, X_scaled)\n",
    "    \n",
    "    qsvc_model = OneClassSVM(kernel='precomputed', nu=0.1)\n",
    "    qsvc_model.fit(K)\n",
    "    \n",
    "    pseudo_labels = qsvc_model.predict(K)\n",
    "    predicted_labels = (pseudo_labels == 1).astype(int)\n",
    "    true_labels = np.ones(rows, dtype=int)\n",
    "    \n",
    "    precision = precision_score(true_labels, predicted_labels, zero_division=0)\n",
    "    recall = recall_score(true_labels, predicted_labels, zero_division=0)\n",
    "    f1 = f1_score(true_labels, predicted_labels, zero_division=0)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    results[app.capitalize()]['QSVM'] = {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1,\n",
    "        'Accuracy': accuracy\n",
    "    }\n",
    "\n",
    "tabulate_data = []\n",
    "for app, kernels_data in results.items():\n",
    "    qsvm_data = kernels_data['QSVM']\n",
    "    row = [\n",
    "        app,\n",
    "        f'{qsvm_data[\"Accuracy\"]:.2f}',\n",
    "        f'{qsvm_data[\"Precision\"]:.2f}',\n",
    "        f'{qsvm_data[\"Recall\"]:.2f}',\n",
    "        f'{qsvm_data[\"F1-score\"]:.2f}'\n",
    "    ]\n",
    "    tabulate_data.append(row)\n",
    "\n",
    "headers = ['Application', 'QSVM Accuracy', 'QSVM Precision', 'QSVM Recall', 'QSVM F1-score']\n",
    "print(tabulate(tabulate_data, headers=headers, tablefmt='grid'))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Application   |   QSVM Accuracy |   QSVM Precision |   QSVM Recall |   QSVM F1-score |\n",
      "+===============+=================+==================+===============+=================+\n",
      "| Blackscholes  |            0.91 |                1 |          0.91 |            0.95 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Bodytrack     |            0.94 |                1 |          0.94 |            0.97 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Canneal       |            0.94 |                1 |          0.94 |            0.97 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| X264          |            0.94 |                1 |          0.94 |            0.97 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Dedup         |            0.94 |                1 |          0.94 |            0.97 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Ferret        |            0.94 |                1 |          0.94 |            0.97 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Fluidanimate  |            0.94 |                1 |          0.94 |            0.97 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Raytrace      |            0.94 |                1 |          0.94 |            0.97 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Streamcluster |            0.94 |                1 |          0.94 |            0.97 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Swaptions     |            0.94 |                1 |          0.94 |            0.97 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Vips          |            0.94 |                1 |          0.94 |            0.97 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Freqmine      |            0.87 |                1 |          0.87 |            0.93 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "from qiskit.circuit.library import ZZFeatureMap, PauliFeatureMap\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "data_scaled = scaler.fit_transform(data_noisy)\n",
    "\n",
    "max_qubits = 4  \n",
    "pca = PCA(n_components=max_qubits)\n",
    "data_reduced = pca.fit_transform(data_scaled)\n",
    "\n",
    "data_reduced = pd.DataFrame(data_reduced, columns=[f'PC{i+1}' for i in range(max_qubits)])\n",
    "\n",
    "applications = {\n",
    "    'blackscholes': 22,\n",
    "    'bodytrack': 18,\n",
    "    'canneal': 18,\n",
    "    'x264': 17,\n",
    "    'dedup': 16,\n",
    "    'ferret': 16,\n",
    "    'fluidanimate': 16,\n",
    "    'raytrace': 16,\n",
    "    'streamcluster': 16,\n",
    "    'swaptions': 16,\n",
    "    'vips': 16,\n",
    "    'freqmine': 15\n",
    "}\n",
    "\n",
    "results = {\n",
    "    app.capitalize(): {\n",
    "        'QSVM': {'Precision': 0, 'Recall': 0, 'F1-score': 0, 'Accuracy': 0}\n",
    "    } for app in applications\n",
    "}\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=max_qubits, reps=3, entanglement='linear')\n",
    "\n",
    "quantum_kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "\n",
    "def kernel_func(X, Y):\n",
    "    return quantum_kernel.evaluate(X, Y)\n",
    "\n",
    "for app, rows in applications.items():\n",
    "    subset_data = data_reduced.iloc[:rows]\n",
    "    X = subset_data.values \n",
    "    \n",
    "    qsvc_model = OneClassSVM(kernel=kernel_func, nu=0.1)\n",
    "    qsvc_model.fit(X)\n",
    "\n",
    "    pseudo_labels = qsvc_model.predict(X)\n",
    "    predicted_labels = (pseudo_labels == 1).astype(int)\n",
    "    true_labels = np.ones(rows, dtype=int) \n",
    "    \n",
    "    precision = precision_score(true_labels, predicted_labels, zero_division=0)\n",
    "    recall = recall_score(true_labels, predicted_labels, zero_division=0)\n",
    "    f1 = f1_score(true_labels, predicted_labels, zero_division=0)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    results[app.capitalize()]['QSVM'] = {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1,\n",
    "        'Accuracy': accuracy\n",
    "    }\n",
    "\n",
    "tabulate_data = []\n",
    "for app, kernels_data in results.items():\n",
    "    qsvm_data = kernels_data['QSVM']\n",
    "    row = [\n",
    "        app,\n",
    "        f'{qsvm_data[\"Accuracy\"]:.2f}',\n",
    "        f'{qsvm_data[\"Precision\"]:.2f}',\n",
    "        f'{qsvm_data[\"Recall\"]:.2f}',\n",
    "        f'{qsvm_data[\"F1-score\"]:.2f}'\n",
    "    ]\n",
    "    tabulate_data.append(row)\n",
    "\n",
    "headers = ['Application', 'QSVM Accuracy', 'QSVM Precision', 'QSVM Recall', 'QSVM F1-score']\n",
    "print(tabulate(tabulate_data, headers=headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Application   |   QSVM Accuracy |   QSVM Precision |   QSVM Recall |   QSVM F1-score |\n",
      "+===============+=================+==================+===============+=================+\n",
      "| Blackscholes  |            0.95 |                1 |          0.95 |            0.98 |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Bodytrack     |            1    |                1 |          1    |            1    |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Canneal       |            1    |                1 |          1    |            1    |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| X264          |            1    |                1 |          1    |            1    |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Dedup         |            1    |                1 |          1    |            1    |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Ferret        |            1    |                1 |          1    |            1    |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Fluidanimate  |            1    |                1 |          1    |            1    |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Raytrace      |            1    |                1 |          1    |            1    |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Streamcluster |            1    |                1 |          1    |            1    |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Swaptions     |            1    |                1 |          1    |            1    |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Vips          |            1    |                1 |          1    |            1    |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n",
      "| Freqmine      |            1    |                1 |          1    |            1    |\n",
      "+---------------+-----------------+------------------+---------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "from qiskit.circuit.library import ZZFeatureMap, PauliFeatureMap\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "data_scaled = scaler.fit_transform(data_noisy)\n",
    "\n",
    "max_qubits = 2 \n",
    "pca = PCA(n_components=max_qubits)\n",
    "data_reduced = pca.fit_transform(data_scaled)\n",
    "\n",
    "data_reduced = pd.DataFrame(data_reduced, columns=['PC1', 'PC2'])\n",
    "\n",
    "applications = {\n",
    "    'blackscholes': 22,\n",
    "    'bodytrack': 18,\n",
    "    'canneal': 18,\n",
    "    'x264': 17,\n",
    "    'dedup': 16,\n",
    "    'ferret': 16,\n",
    "    'fluidanimate': 16,\n",
    "    'raytrace': 16,\n",
    "    'streamcluster': 16,\n",
    "    'swaptions': 16,\n",
    "    'vips': 16,\n",
    "    'freqmine': 15\n",
    "}\n",
    "\n",
    "results = {\n",
    "    app.capitalize(): {\n",
    "        'QSVM': {'Precision': 0, 'Recall': 0, 'F1-score': 0, 'Accuracy': 0}\n",
    "    } for app in applications\n",
    "}\n",
    "\n",
    "feature_map = PauliFeatureMap(feature_dimension=max_qubits, reps=3, entanglement='linear')\n",
    "\n",
    "quantum_kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "\n",
    "def kernel_func(X, Y):\n",
    "    return quantum_kernel.evaluate(X, Y)\n",
    "\n",
    "for app, rows in applications.items():\n",
    "    subset_data = data_reduced.iloc[:rows]\n",
    "    X = subset_data.values \n",
    "\n",
    "    qsvc_model = OneClassSVM(kernel=kernel_func, nu=0.1)\n",
    "    qsvc_model.fit(X)\n",
    "\n",
    "    pseudo_labels = qsvc_model.predict(X)\n",
    "    predicted_labels = (pseudo_labels == 1).astype(int)\n",
    "    true_labels = np.ones(rows, dtype=int) \n",
    "\n",
    "    precision = precision_score(true_labels, predicted_labels, zero_division=0)\n",
    "    recall = recall_score(true_labels, predicted_labels, zero_division=0)\n",
    "    f1 = f1_score(true_labels, predicted_labels, zero_division=0)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    results[app.capitalize()]['QSVM'] = {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1,\n",
    "        'Accuracy': accuracy\n",
    "    }\n",
    "\n",
    "tabulate_data = []\n",
    "for app, kernels_data in results.items():\n",
    "    qsvm_data = kernels_data['QSVM']\n",
    "    row = [\n",
    "        app,\n",
    "        f'{qsvm_data[\"Accuracy\"]:.2f}',\n",
    "        f'{qsvm_data[\"Precision\"]:.2f}',\n",
    "        f'{qsvm_data[\"Recall\"]:.2f}',\n",
    "        f'{qsvm_data[\"F1-score\"]:.2f}'\n",
    "    ]\n",
    "    tabulate_data.append(row)\n",
    "\n",
    "headers = ['Application', 'QSVM Accuracy', 'QSVM Precision', 'QSVM Recall', 'QSVM F1-score']\n",
    "print(tabulate(tabulate_data, headers=headers, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.visualization import circuit_drawer\n",
    "\n",
    "num_qubits = 2\n",
    "feature_map_2q = ZZFeatureMap(feature_dimension=num_qubits, reps=1, entanglement='linear')\n",
    "circuit_2q = feature_map_2q.decompose()\n",
    "circuit_drawer(circuit_2q, output='mpl', filename='quantum_circuit_2qubits.png')\n",
    "\n",
    "num_qubits = 4\n",
    "feature_map_4q = ZZFeatureMap(feature_dimension=num_qubits, reps=1, entanglement='linear')\n",
    "circuit_4q = feature_map_4q.decompose()\n",
    "circuit_drawer(circuit_4q, output='mpl', filename='quantum_circuit_4qubits.png')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
